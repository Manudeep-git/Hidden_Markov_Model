{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markov_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Ql8WzMULf_"
      },
      "source": [
        "# Word generation and prediction using Hidden Markov Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSXPdKtlUYRr"
      },
      "source": [
        "The aim of this project is to design a algorithm similar to hidden markov model to learn correlations and distributions to\n",
        "  1. Generate new text from given text corpus dataset\n",
        "  2. Perform text prediction from given sequence of words\n",
        " \n",
        "Dataset Used: <a src=\"https://www.kaggle.com/kingburrito666/shakespeare-plays?select=Shakespeare_data.csv\">Shakespeare-plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDkUVRG_9TD-"
      },
      "source": [
        "## **Process**:\n",
        "\n",
        "1.  Dataset is loaded into pandas and cleaned giving list of all player-lines\n",
        "2.   Markov model is build and trained\n",
        "    *   First of all, each line is tokenized from player-lines of dataset\n",
        "    *  Markov chains are built based on generated tokens\n",
        "3. ***generate_text()*** function makes use of ***sample_word()*** which given a word  generates a full play sentence  based on pre-built markov chains built using ***build_and_train_markov_model()***\n",
        "4. ***text_prediction()*** function predicts text based on given sentence \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQoK8tvKVMUV"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ5hUlJFEeHf"
      },
      "source": [
        "import string \n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af3-0WCzCdGm"
      },
      "source": [
        "## Dataset Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViVFFjSUCqGr"
      },
      "source": [
        "The following main goals are achieved in this section:\n",
        "\n",
        "\n",
        "1. Dataset is loaded\n",
        "2. Uninteresting lines are deleted from the dataset \n",
        "3. Lines are converted into a list of string for further processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "7RNJzrlyDCx-",
        "outputId": "c1944b3c-7fd2-4205-bbc6-8eb5a4228cbd"
      },
      "source": [
        "df = pd.read_csv ('/content/Shakespeare_data.csv') ##replace content with data when executing \n",
        "df.head ()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACT I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SCENE I. London. The palace.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.1</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.2</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dataline  ...                                         PlayerLine\n",
              "0         1  ...                                              ACT I\n",
              "1         2  ...                       SCENE I. London. The palace.\n",
              "2         3  ...  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...\n",
              "3         4  ...             So shaken as we are, so wan with care,\n",
              "4         5  ...         Find we a time for frighted peace to pant,\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "GLjxXNSyDOEQ",
        "outputId": "1b2a7297-329a-402a-cf07-b2792510b8dc"
      },
      "source": [
        "# Keep valid lines (i.e., spoken by a player) only\n",
        "df = df.dropna (subset = ['Player', 'ActSceneLine'])\n",
        "df.sample (5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>106306</th>\n",
              "      <td>106307</td>\n",
              "      <td>Two Gentlemen of Verona</td>\n",
              "      <td>53.0</td>\n",
              "      <td>2.4.92</td>\n",
              "      <td>VALENTINE</td>\n",
              "      <td>To see such lovers, Thurio, as yourself:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>4598</td>\n",
              "      <td>Henry VI Part 1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.1.154</td>\n",
              "      <td>GLOUCESTER</td>\n",
              "      <td>So help me God, as I dissemble not!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76201</th>\n",
              "      <td>76202</td>\n",
              "      <td>Pericles</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4.18</td>\n",
              "      <td>CLEON</td>\n",
              "      <td>I'll then discourse our woes, felt several years,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24117</th>\n",
              "      <td>24118</td>\n",
              "      <td>A Comedy of Errors</td>\n",
              "      <td>36.0</td>\n",
              "      <td>5.1.104</td>\n",
              "      <td>ADRIANA</td>\n",
              "      <td>Diet his sickness, for it is my office,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76348</th>\n",
              "      <td>76349</td>\n",
              "      <td>Pericles</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.1.5</td>\n",
              "      <td>PERICLES</td>\n",
              "      <td>Alas, the sea hath cast me on the rocks,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Dataline  ...                                         PlayerLine\n",
              "106306    106307  ...           To see such lovers, Thurio, as yourself:\n",
              "4597        4598  ...                So help me God, as I dissemble not!\n",
              "76201      76202  ...  I'll then discourse our woes, felt several years,\n",
              "24117      24118  ...            Diet his sickness, for it is my office,\n",
              "76348      76349  ...           Alas, the sea hath cast me on the rocks,\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqv9bDtNDP8D",
        "outputId": "6954e365-492c-4280-cd0a-977d1a356619"
      },
      "source": [
        "lines = df ['PlayerLine'].tolist ()\n",
        "print(lines [10:15])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['All of one nature, of one substance bred,', 'Did lately meet in the intestine shock', 'And furious close of civil butchery', 'Shall now, in mutual well-beseeming ranks,', 'March all one way and be no more opposed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8udkzh71VX-Q"
      },
      "source": [
        "#data = \"/content/alllines.txt\" ##replace content with data when executing "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix9JAfKQVwzl"
      },
      "source": [
        "## Pre-processing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5DGGkiaWCMZ"
      },
      "source": [
        "Let's remove some special characters in each line of text for better results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkEwP_TBVtnl"
      },
      "source": [
        "def removeSpecial(line):\n",
        "  return line.translate(str.maketrans(\"\",\"\",string.punctuation))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Ra1nCIZ22s"
      },
      "source": [
        "Creating a hashmap/dictionary for storing key-value pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnW4OYAPYlfa"
      },
      "source": [
        "def create_dict(dictionary, key, value):\n",
        "  if key not in dictionary:\n",
        "      dictionary[key]=[]\n",
        "  dictionary[key].append(value)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Pa74zfZyav"
      },
      "source": [
        "Creating a probability dict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qV6Km1OZHEk"
      },
      "source": [
        "def create_probability_dict(text_data):\n",
        "    prob_dict = {}\n",
        "    text_data_len = len(text_data)\n",
        "    for item in text_data:\n",
        "        prob_dict[item] = prob_dict.get(item, 0) + 1\n",
        "    for key, value in prob_dict.items():\n",
        "        prob_dict[key] = value / text_data_len\n",
        "    return prob_dict"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO3pYEfKZ7IT"
      },
      "source": [
        "Now we need some data-structure to hold initial states and trnasition states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoMYT2aVaETB"
      },
      "source": [
        "initial_word= {}\n",
        "second_word = {}\n",
        "transitions = {}"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGaZqSQCbuJB"
      },
      "source": [
        "## Building and Training the Markov Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHI0aCWrb_f8"
      },
      "source": [
        "One important property about markov model is that the **next step** depends on only the **current step** and not on the past historical steps\n",
        "\n",
        "For this project, I'm gonna make use of the same "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdiaR4uecgpL"
      },
      "source": [
        "The training of the Markov model can be divided into the following stages -\n",
        "1. Cleaning  up data and Tokenisation\n",
        "2. Building the state pairs(previous and current)\n",
        "3. Determining the probability distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya9ezNsDb4bI"
      },
      "source": [
        "# Trains a Markov model based on the data in data_file\n",
        "def build_and_train_markov_model():\n",
        "    for line in lines:\n",
        "\n",
        "        #tokenizing data\n",
        "        tokens = removeSpecial(line.rstrip().lower()).split()\n",
        "        tokens_length = len(tokens)\n",
        "\n",
        "        #next and current state-pairs\n",
        "        for i in range(tokens_length):\n",
        "            token = tokens[i]\n",
        "\n",
        "            #Initial state need not be calculated for 1st token\n",
        "            if i == 0:\n",
        "                initial_word[token] = initial_word.get(token, 0) + 1\n",
        "            else:\n",
        "                prev_token = tokens[i - 1]\n",
        "\n",
        "                ##additional token for last-item\n",
        "                if i == tokens_length - 1:\n",
        "                    create_dict(transitions, (prev_token, token), 'END')\n",
        "                if i == 1:\n",
        "                    create_dict(second_word, prev_token, token)\n",
        "                else:\n",
        "                    prev_prev_token = tokens[i - 2]\n",
        "                    create_dict(transitions, (prev_prev_token, prev_token), token)\n",
        "    \n",
        "    # Normalize the distributions\n",
        "    initial_word_total = sum(initial_word.values())\n",
        "    for key, value in initial_word.items():\n",
        "        initial_word[key] = value / initial_word_total\n",
        "        \n",
        "    for prev_word, next_word_list in second_word.items():\n",
        "        second_word[prev_word] = create_probability_dict(next_word_list)\n",
        "        \n",
        "    for word_pair, next_word_list in transitions.items():\n",
        "        transitions[word_pair] = create_probability_dict(next_word_list)\n",
        "    \n",
        "    print('Building and Training finished')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQGUvxpGd5tE",
        "outputId": "b0fab9ad-ef32-4a04-c472-a29e0d4f728c"
      },
      "source": [
        "build_and_train_markov_model()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building and Training finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y0f_OEIeKWj"
      },
      "source": [
        "## 1.Generating new text from corpus using **Built Hidden Markov Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ-jZHrEedXG"
      },
      "source": [
        "Once we have completed the training, we will have the initial word distribution, second-word distribution and the state transition distributions. Next to generate a text corpus all we need is to write a function to sample out from the above-created distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBp4Zl4teeHp"
      },
      "source": [
        "def sample_word(dictionary):\n",
        "    p0 = np.random.random()\n",
        "    cumulative = 0\n",
        "    for key, value in dictionary.items():\n",
        "        cumulative += value\n",
        "        if p0 < cumulative:\n",
        "            return key\n",
        "    assert(False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aExeYtuAeh8H"
      },
      "source": [
        "#Fixing our generated text to length 15\n",
        "number_of_sentences = 12"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gwKRYQGenLL"
      },
      "source": [
        "def generate_text():\n",
        "    for i in range(number_of_sentences):\n",
        "        sentence = []\n",
        "        # Initial word\n",
        "        word0 = sample_word(initial_word)\n",
        "        sentence.append(word0)\n",
        "        # Second word\n",
        "        word1 = sample_word(second_word[word0])\n",
        "        sentence.append(word1)\n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            word2 = sample_word(transitions[(word0, word1)])\n",
        "            if word2 == 'END':\n",
        "                break\n",
        "            sentence.append(word2)\n",
        "            word0 = word1\n",
        "            word1 = word2\n",
        "        print(' '.join(sentence))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu1lntFyen_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aecfcf3-acb4-46aa-85ee-aa7fa9e63ecd"
      },
      "source": [
        "generate_text()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "more bound his training such\n",
            "come if it were otherwise that i might have saved my longing and i more incline to somerset than york\n",
            "i prithee more\n",
            "sometime like god bels\n",
            "words and thereupon i will show thee where they would fly east west north south\n",
            "dost thou look\n",
            "no my chuck eros come mine armour\n",
            "good honest men\n",
            "not that use them\n",
            "shallow and another shall\n",
            "when we were awaked straightway at liberty\n",
            "truly the souls of friend and will lead you to do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR7X40nseuqI"
      },
      "source": [
        "## 2.Performing text prediction given a sequence of words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEgFBCeexGB"
      },
      "source": [
        "def text_prediction(text):\n",
        "        text = removeSpecial(text.lower()).split()\n",
        "        # Initial word\n",
        "        word0 = text[0]\n",
        "        # Second word\n",
        "        if len(text) == 1:\n",
        "            word1 = sample_word(second_word[word0])\n",
        "            text.append(word1)\n",
        "        else:\n",
        "            word1 = text[1]\n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            word2 = max(transitions[(word0, word1)], key=transitions[(word0, word1)].get)\n",
        "            if word2 == 'END':\n",
        "                break\n",
        "            text.append(word2)\n",
        "            word0 = word1\n",
        "            word1 = word2\n",
        "        print(' '.join(text))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz59Qi-ze4YS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa97bde-5318-410e-d005-79e65b5b1fe4"
      },
      "source": [
        "#Testing\n",
        "text_prediction(\"walking with\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "walking with thee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKSWUFJGe9F-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abaf0c7d-f0f0-40d6-bd09-199e53af462c"
      },
      "source": [
        "text_prediction(\"cudgel him\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cudgel him like a man\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX_7z51fE5q7"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbpEapVmFA2D"
      },
      "source": [
        "To conclude, i think the text-generation of the markov model is working pretty well and prediction is reasonably good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZZ_8viFZlc"
      },
      "source": [
        "**References** : \n",
        "\n",
        "1. https://towardsdatascience.com/markov-and-hidden-markov-model-3eec42298d75\n",
        "2. https://en.wikipedia.org/wiki/Hidden_Markov_model\n",
        "3. https://medium.com/@kangeugine/hidden-markov-model-7681c22f5b9"
      ]
    }
  ]
}